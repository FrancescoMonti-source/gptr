# gptr ‚Äî Structured Data Extraction from Free Text with LLMs

`gptr` is an R package that turns messy, domain-specific text into tidy, validated variables using large language models (LLMs).

It‚Äôs **model-agnostic** (local or API), robust to imperfect outputs, and designed for **reproducible pipelines** in research or production.

------------------------------------------------------------------------

## ‚ú® Why use gptr

-   Consistent, validated outputs from LLMs ‚Äî no manual cleanup
-   Works with both **local** (LM Studio, Ollama, LocalAI) and **API** (OpenAI, Mistral) models
-   Built for **data pipelines** ‚Äî tidyverse-friendly, parallel-ready
-   Rich diagnostics: raw outputs, invalid row tracking, retry helpers

------------------------------------------------------------------------

## üì¶ Installation

``` r
# Install from GitHub
remotes::install_github("FrancescoMonti-source/gptr")
```

------------------------------------------------------------------------

## üöÄ Quick start

``` r
library(gptr)
library(tibble)

# Define a prompt template
template <- "Extract age and diagnosis from:\n{text}\nFormat: {json_format}"

# Example data
df <- tibble(
  id   = 1,
  note = "Patient is 64 years old, diagnosed with type 2 diabetes."
)

# Run extraction
res <- gpt_column(
  data   = df,
  col    = note,
  prompt = template,  # placeholders {text} and {json_format} are filled automatically
  keys   = list(
    age       = "integer",
    diagnosis = "character"
  ),
  provider     = "openai",       # or "lmstudio"
  model        = "gpt-4o-mini",  # change to your model
  temperature  = 0.2,
  return_debug = TRUE
)

res
```

------------------------------------------------------------------------

## üîç How it works ‚Äî the big picture

```         
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ LAYER 3 ‚Äî ORCHESTRATION                                             ‚îÇ
‚îÇ  gpt_column()                                                       ‚îÇ
‚îÇ   ‚îú‚îÄ loops over data[[col]]                                         ‚îÇ
‚îÇ   ‚îú‚îÄ progress + ETA (progressr)                                     ‚îÇ
‚îÇ   ‚îú‚îÄ optional parallel (furrr)                                      ‚îÇ
‚îÇ   ‚îú‚îÄ attaches .raw_output / .invalid_rows                           ‚îÇ
‚îÇ   ‚îî‚îÄ binds per-row tibble rows back to original data                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ per row
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ LAYER 2 ‚Äî MID-LEVEL (one-row pipeline)                              ‚îÇ
‚îÇ  1) trim_text()                               (preprocess)          ‚îÇ
‚îÇ  2) build_prompt() ‚Üê json_format_from_keys()  (prompt)              ‚îÇ
‚îÇ  3) gpt()                                        (LLM call)         ‚îÇ
‚îÇ  4) tidy_json() ‚Üí jsonlite::fromJSON()          (repair+parse)      ‚îÇ
‚îÇ  5) coerce_type() / in_allowed() / is_na_like() (validate)          ‚îÇ
‚îÇ  6) match_arg_tol() + fill-missing             (align keys)         ‚îÇ
‚îÇ  7) row_to_tibble()                            (shape output)       ‚îÇ
‚îÇ  (If relaxed && no keys: skip validation/alignment; return raw/parsed)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚ñ≤                 ‚ñ≤
                 ‚îÇ                 ‚îÇ uses
                 ‚îÇ                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ LAYER 1 ‚Äî LOW-LEVEL UTILITIES                                       ‚îÇ
‚îÇ  %||%, normalize_token(), parse_key_spec(), coerce_type(),          ‚îÇ
‚îÇ  in_allowed(), is_na_like(), tidy_json(), match_arg_tol(), trim_text() ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

------------------------------------------------------------------------

## üìñ Core API

-   **`gpt_column()`** ‚Äî Main orchestrator: builds prompts, calls model, repairs/parses JSON, validates, aligns keys, returns tibble. Supports progress, ETA, parallel, debug columns.
-   **`build_prompt()`** ‚Äî Injects `{text}` and `{json_format}` into your prompt template, using `keys` to document allowed values.
-   **Key utilities** (used internally, available to you):
    -   `trim_text()`, `tidy_json()`, `parse_key_spec()`, `coerce_type()`, `in_allowed()`, `match_arg_tol()`, `is_na_like()`, `%||%`, `normalize_token()`

> All functions link via `@seealso` in pkgdown for easy navigation.

------------------------------------------------------------------------

## üóù Designing keys & prompts

`keys` is a **named list** that defines the variables to extract and their expected types: - `"integer"`, `"numeric"`, `"character"`, `"logical"`, or - a **set of allowed values**: e.g., `c("l√©ger", "mod√©r√©", "s√©v√®re")`

Example:

``` r
keys <- list(
  impulsivite = "integer",
  severite    = c("l√©ger", "mod√©r√©", "s√©v√®re")
)
```

These guide the LLM and enable strict validation (`coerce_type()`, `in_allowed()`).

### Prompt templates

When `prompt` is a character template: - **`{text}`** ‚Üí replaced with the current row's text from `col` - **`{json_format}`** ‚Üí a JSON skeleton from `keys`, showing expected fields and allowed values

Example:

``` r
tpl <- paste0(
  'Tu es un assistant d\'extraction structur√©e.',
  '\nTexte: "{text}"',
  '\nRenvoie STRICTEMENT un JSON une seule ligne: {json_format}'
)
```

Example JSON format for:

``` r
keys = list(age = "integer", diagnosis = c("diabetes", "hypertension"))
```

would be:

``` json
{"age": "0"|"1"|"NA", "diagnosis": "diabetes"|"hypertension"}
```

You can also pass a **function** to `prompt` for full control.

------------------------------------------------------------------------

## ‚ö° Parallel & progress

``` r
library(future)
future::plan(multisession, workers = 4)

res <- gpt_column(
  data = df,
  col = notes,
  prompt = tpl,
  keys = keys,
  parallel = TRUE
)
```

Progress and ETA are provided via `progressr`.

------------------------------------------------------------------------

## üêû Debugging

-   `return_debug = TRUE` (default) adds:
    -   `.raw_output` ‚Äî model‚Äôs raw string per row
    -   `.invalid_rows` ‚Äî rows failing parsing/validation
-   `show_invalid_rows = TRUE` prints offending inputs

------------------------------------------------------------------------

## üîÅ Retrying failed rows

If some rows fail schema validation, `gpt_column()` tags them in the `"invalid_rows"` attribute.

``` r
attr(res, "invalid_rows")

res2 <- patch_failed_rows(
  data   = res,
  prompt = template,
  col    = note,
  id_col = id,
  keys   = list(
    age       = "integer",
    diagnosis = "character"
  ),
  max_attempts = 2
)

attr(res2, "invalid_rows")
```

------------------------------------------------------------------------

## üí¨ Multi-turn conversations

``` r
gpt_chat("Hi! My name is Bob.")
gpt_chat("What's my name?")
gpt_chat(show_history = TRUE)
gpt_chat(reset = TRUE)  # start fresh
```

Multi-turn chat works with all supported providers (see below).

------------------------------------------------------------------------

## üîó Supported providers

-   **LM Studio** (local inference server, OpenAI-compatible API)
-   **OpenAI** (`gpt-4o`, `gpt-4o-mini`, `gpt-3.5-turbo`, `gpt-4.1`, etc.)
-   Any OpenAI-compatible endpoint (self-hosted models, fine-tuned endpoints, etc.)

------------------------------------------------------------------------

## üìÑ License

MIT License ‚Äî see [LICENSE.md](LICENSE.md)

------------------------------------------------------------------------

## üõ† Requirements

-   R ‚â• 4.1
-   Packages: `httr`, `httr2`, `tidyverse`, `jsonlite`, `stringr`, `purrr`, `tools`, `cli`
-   Suggested: `furrr`, `pdftools`, `officer`, `mime`

------------------------------------------------------------------------

## ü§ù Contributing

Issues and pull requests are welcome. Please open an issue to discuss proposed changes before submitting a PR.

------------------------------------------------------------------------

## üìö See also

-   [OpenAI API documentation](https://platform.openai.com/docs/)
-   [LM Studio](https://lmstudio.ai/)
-   [furrr parallel docs](https://furrr.futureverse.org/)
