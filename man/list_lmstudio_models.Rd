% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/list_lmstudio_models.R
\name{list_lmstudio_models}
\alias{list_lmstudio_models}
\title{List Available Models from an LM Studio API Server}
\usage{
list_lmstudio_models(url = "http://127.0.0.1:1234/v1/models")
}
\arguments{
\item{url}{Character string giving the base URL of the LM Studio models endpoint.
Defaults to \code{"http://127.0.0.1:1234/v1/models"}, which is the default
local server URL for LM Studio.}
}
\value{
A \link[tibble:tibble]{tibble} where each row represents a model and columns
typically include:
\describe{
\item{\code{id}}{The model identifier (e.g., \code{"mistralai/mistral-7b-instruct-v0.3"}).}
\item{\code{object}}{The type of object, usually \code{"model"}.}
\item{\code{owned_by}}{The owner or source of the model (e.g., \code{"organization_owner"}).}
Additional columns may be returned depending on LM Studio's API version.
}
}
\description{
Retrieves and returns the list of models available from a running
\href{https://lmstudio.ai}{LM Studio} API endpoint.
}
\details{
This function sends a GET request to the specified LM Studio API endpoint,
parses the JSON response, and converts the \code{data} field into a tidy tibble.

It will raise an error if the request fails (e.g., LM Studio server is not running,
wrong port, or invalid endpoint).
}
\examples{
\dontrun{
# List models from a locally running LM Studio server:
list_lmstudio_models()

# List models from a remote LM Studio instance:
list_lmstudio_models("http://192.168.1.50:1234/v1/models")
}

}
\seealso{
\itemize{
\item \code{\link[httr:GET]{httr::GET()}} for making HTTP requests.
\item \code{\link[jsonlite:fromJSON]{jsonlite::fromJSON()}} for parsing JSON.
\item LM Studio API docs: https://lmstudio.ai
}
}
