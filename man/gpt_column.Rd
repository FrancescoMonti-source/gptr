% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gpt_column.R
\name{gpt_column}
\alias{gpt_column}
\title{Extract Structured Data from Free Text via LLM Completion (Orchestrator)}
\usage{
gpt_column(
  data,
  col,
  prompt,
  keys = NULL,
  provider = c("local", "openai"),
  temperature = 0,
  file_path = NULL,
  image_path = NULL,
  coerce_types = TRUE,
  coerce_when = NULL,
  final_types = c("schema", "infer", "as_is"),
  na_values = c("NA", "N/A", "null", "None", ""),
  auto_correct_keys = getOption("gptr.auto_correct_keys", TRUE),
  keep_unexpected_keys = getOption("gptr.keep_unexpected_keys", FALSE),
  fuzzy_model = getOption("gptr.fuzzy_model", "lev_ratio"),
  fuzzy_threshold = getOption("gptr.fuzzy_threshold", 0.3),
  relaxed = FALSE,
  return_debug = FALSE,
  verbose = FALSE,
  ...
)
}
\arguments{
\item{data}{A data frame or tibble containing the text column.}

\item{col}{Unquoted name of the text column to send to the LLM.}

\item{prompt}{Character template with {text}/{json_format} or function(text, keys) -> string.}

\item{keys}{Optional named list defining expected JSON keys and their type or allowed set.}

\item{temperature}{Sampling temperature for the model.}

\item{file_path, image_path}{Optional file paths passed to the model call.}

\item{coerce_types}{Row-level coercion toggle (default TRUE).}

\item{coerce_when}{Optional predicate function(key, value, spec, row_index) -> TRUE/FALSE for per-value control.}

\item{final_types}{Final column typing: "schema" (default), "infer", or "as_is".}

\item{na_values}{Values treated as NA at multiple stages.}

\item{auto_correct_keys}{Logical; fuzzy-correct unexpected key names (unique match only). Fuzzy key correction is handled by json_keys_align(). You can control it by passing fuzzy_model ("lev_ratio" or "lev") and fuzzy_threshold via .... Defaults: fuzzy_model = "lev_ratio", fuzzy_threshold = 0.3.}

\item{keep_unexpected_keys}{Keep keys not listed in \code{keys}.}

\item{relaxed}{If TRUE and \code{keys} is NULL, allow non-JSON / raw outputs.}

\item{return_debug}{If TRUE, add \code{.raw_output} and \code{.invalid_rows}.}

\item{verbose}{Print repair/validation messages.}

\item{...}{Extra args passed to \code{gpt()}.}

\item{max.distance}{Max distance for fuzzy key matching (agrep).}

\item{show_invalid_rows}{Print offending inputs (by index) if validation fails.}

\item{parallel}{If TRUE, use \code{furrr} to parallelize.}

\item{max_tokens}{Token limit for trim_text().}

\item{token_mode}{"words", "chars", or "custom" for trim_text().}

\item{custom_tokenizer}{Optional custom tokenizer for trim_text().}
}
\description{
Sends each row of a text column to an LLM with a templated prompt, repairs/parses JSON,
validates and aligns it to a schema, then returns the structured columns bound to the input.
}
